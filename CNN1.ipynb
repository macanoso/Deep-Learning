{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJvUoeLXTJ0S"
      },
      "source": [
        "# DOGs & Cats Revisited !\n",
        "\n",
        "A baseline model will establish a minimum model performance to which all of our other models can be compared, as well as a model architecture that we can use as the basis of study and improvement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaetiSygGi06",
        "outputId": "e8abc49c-7d77-4bc2-ee3e-04c908d7e18f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "base_dir is:  /content/drive/My Drive/Deep Learning/CNN/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "root_dir = \"/content/drive/My Drive/\"\n",
        "base_dir = root_dir + 'Deep Learning/CNN/'\n",
        "print(\"base_dir is: \", base_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGZ5-JsUUl7p"
      },
      "source": [
        "A good starting point is the general architectural principles of the VGG models. It achieved top performance in the ILSVRC 2014 competition and the modular structure of the architecture is easy to understand and implement. For more details on the VGG model, see the 2015 paper: [“Very Deep Convolutional Networks for Large-Scale Image Recognition.”](https://arxiv.org/abs/1409.1556)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NP9EX9tUH3t"
      },
      "outputs": [],
      "source": [
        "# System libraries\n",
        "import os\n",
        "\n",
        "# Keras libraries\n",
        "from keras.preprocessing.image import ImageDataGenerator  ## Para el preprocesamiento de imagenes\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS_EV3OPT5Ns"
      },
      "source": [
        "The architecture involves stacking convolutional layers with small 3×3 filters followed by a max pooling layer. Together, these layers form a block, and these blocks can be repeated where the number of filters in each block is increased with the depth of the network such as 32, 64, 128, 256 for the first four blocks of the model. Padding is used on the convolutional layers to ensure the height and width shapes of the output feature maps matches the inputs.\n",
        "\n",
        "Each layer will use the ReLU activation function and the He weight initialization, which are generally best practices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNQxV6xnUIHY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "eef0c6b5-de9e-4aa3-88a0-549bdf4752fa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9971e98a856e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# block 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'he_uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# block 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'he_uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# block 1\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "# block 2\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "# block 3\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Va0QPFDUb1a"
      },
      "source": [
        "## One VGG Block\n",
        "We can create a function named define_model() that will define a model and return it ready to be fit on the dataset. This function can then be customized to define different baseline models, e.g. versions of the model with 1, 2, or 3 VGG style blocks.\n",
        "\n",
        "The model will be fit with stochastic gradient descent and we will start with a conservative learning rate of 0.001 and a momentum of 0.9.\n",
        "\n",
        "The problem is a binary classification task, requiring the prediction of one value of either 0 or 1. An output layer with 1 node and a sigmoid activation will be used and the model will be optimized using the binary cross-entropy loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhIqog16UJQP"
      },
      "outputs": [],
      "source": [
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLxvL9hR3Wr_",
        "outputId": "c015e8ad-d33a-4990-b165-4d03f165a800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> train dogs: 4000\n",
            "> test cats: 1029\n"
          ]
        }
      ],
      "source": [
        "print('> train dogs:',len(os.listdir(os.path.join(base_dir, 'dataset_dogs_vs_cats/train/dogs/'))))\n",
        "print('> test cats:',len(os.listdir(os.path.join(base_dir, 'dataset_dogs_vs_cats/test/cats/'))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUDb52h0WQjG"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "model = define_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbMwDcntWQxq"
      },
      "outputs": [],
      "source": [
        "# create data generator\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjyibE1mWyk0",
        "outputId": "379e4588-9fc3-4fd2-b3dd-4e21ac2d7c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2029 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# prepare iterators\n",
        "train_it = datagen.flow_from_directory(os.path.join(base_dir, 'dataset_dogs_vs_cats/train/'),\n",
        "\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "test_it = datagen.flow_from_directory(os.path.join(base_dir, 'dataset_dogs_vs_cats/test/'),\n",
        "\tclass_mode='binary', batch_size=64, target_size=(200, 200))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDJKk8BHX6BM"
      },
      "source": [
        "We can then fit the model using the train iterator (train_it) and use the test iterator (test_it) as a validation dataset during training.\n",
        "\n",
        "The number of steps for the train and test iterators must be specified. This is the number of batches that will comprise one epoch. This can be specified via the length of each iterator, and will be the total number of images in the train and test directories divided by the batch size (64).\n",
        "\n",
        "The model will be fit for 20 epochs, a small number to check if the model can learn the problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k52AFj0NXNso",
        "outputId": "2c2a8340-834e-447d-9eea-94912698a12c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "# fit model\n",
        "history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
        "\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThjMIr43YSaX"
      },
      "source": [
        "Once fit, the final model can be evaluated on the test dataset directly and the classification accuracy reported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3okcSMkYTO8",
        "outputId": "b078b56d-73f9-40c2-c58c-f42d8bce421e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> 68.162\n"
          ]
        }
      ],
      "source": [
        "# evaluate model\n",
        "_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch6huWv1ZAfl"
      },
      "source": [
        "Finally, we can create a plot of the history collected during training stored in the “history” directory returned from the call to fit().\n",
        "\n",
        "The History contains the model accuracy and loss on the test and training dataset at the end of each epoch. Line plots of these measures over training epochs provide learning curves that we can use to get an idea of whether the model is overfitting, underfitting, or has a good fit.\n",
        "\n",
        "The summarize_diagnostics() function below takes the history directory and creates a single figure with a line plot of the loss and another for the accuracy. The figure is then saved to file with a filename based on the name of the script. This is helpful if we wish to evaluate many variations of the model in different files and create line plots automatically for each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWKWkhElFp3A"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "import sys\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(os.path.join(base_dir, filename + '_plot.png'))\n",
        "\tpyplot.close()\n",
        "\n",
        "summarize_diagnostics(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K8B_6XaIlRm"
      },
      "source": [
        "## Two Block VGG Model\n",
        "It extends the one block VGG model and adds a second block with 64 filters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nyw0rHX8IW-P",
        "outputId": "53992cf7-1fc5-4830-8763-bb066f9bed44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2029 images belonging to 2 classes.\n",
            "> 73.386\n"
          ]
        }
      ],
      "source": [
        "# baseline model for the dogs vs cats dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(os.path.join(base_dir, filename + '_plot2VGGBlock.png'))\n",
        "\tpyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\t# prepare iterators\n",
        "\ttrain_it = datagen.flow_from_directory(os.path.join(base_dir, 'dataset_dogs_vs_cats/train/'),\n",
        "\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = datagen.flow_from_directory(os.path.join(base_dir, 'dataset_dogs_vs_cats/test/'),\n",
        "\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\t# fit model\n",
        "\thistory = model.fit(train_it, steps_per_epoch=len(train_it),\n",
        "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFahNB5xVsKn"
      },
      "source": [
        "Your results may vary given the stochastic nature of the algorithm, evaluation procedure, number of images, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
        "\n",
        "In this case, we can see that the model achieved a small improvement in performance from about 68% with one block to about 73% accuracy with two blocks (5 points).\n",
        "\n",
        "Reviewing the plot of the learning curves, we can see that again the model appears to have overfit the training dataset, perhaps sooner, in this case at around eight training epochs.\n",
        "\n",
        "This is likely the result of the increased capacity of the model, and we might expect this trend of sooner overfitting to continue with the next model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MbGERa1WnH7"
      },
      "source": [
        "## Three Block VGG Model\n",
        "The three-block VGG model extends the two block model and adds a third block with 128 filters.\n",
        "\n",
        "The define_model() function for this model was defined in the previous section but is provided again below for completeness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp8PNxP_WDla",
        "outputId": "fdcd8009-28c6-4662-f21c-47308632e5d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2029 images belonging to 2 classes.\n",
            "> 76.885\n"
          ]
        }
      ],
      "source": [
        "# baseline model for the dogs vs cats dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(os.path.join(base_dir, filename + '_plot3VGGBlock.png'))\n",
        "\tpyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\t# prepare iterators\n",
        "\ttrain_it = datagen.flow_from_directory(os.path.join(base_dir, 'dataset_dogs_vs_cats/train/'),\n",
        "\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = datagen.flow_from_directory(os.path.join(base_dir, 'dataset_dogs_vs_cats/test/'),\n",
        "\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\t# fit model\n",
        "\thistory = model.fit(train_it, steps_per_epoch=len(train_it),\n",
        "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbR5NK84aX-c"
      },
      "source": [
        "In this case, we can see that we achieved a further lift in performance from about 73% with two blocks to about 77% accuracy with three blocks. This result is good, as it is close to the prior state-of-the-art reported in the paper using an SVM at about 82% accuracy.\n",
        "\n",
        "Reviewing the plot of the learning curves, we can see a similar trend of overfitting, in this case perhaps pushed back as far as to epoch five or six."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paYNxPnHakF-"
      },
      "source": [
        "## Discussion\n",
        "\n",
        "VGG 1: 68.162%\n",
        "\n",
        "VGG 2: 73.386%\n",
        "\n",
        "VGG 3: 76.885%\n",
        "\n",
        "We see a trend of improved performance with the increase in capacity, but also a similar case of overfitting occurring earlier and earlier in the run.\n",
        "\n",
        "The results suggest that the model will likely benefit from regularization techniques. This may include techniques such as dropout, weight decay, and data augmentation. The latter can also boost performance by encouraging the model to learn features that are further invariant to position by expanding the training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox3Knw-Ka3wj"
      },
      "source": [
        "## Model Improvements\n",
        "Both of these approaches are expected to slow the rate of improvement during training and hopefully counter the overfitting of the training dataset. As such, we will increase the number of training epochs from 20 to 40 to give the model more space for refinement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLwJReFzbVDL"
      },
      "source": [
        "## Dropout Regularization\n",
        "\n",
        "It is a computationally cheap way to regularize a deep neural network. It works by probabilistically removing, or “dropping out,” inputs to a layer, which may be input variables in the data sample or activations from a previous layer. It has the effect of simulating a large number of networks with very different network structures and, in turn, making nodes in the network generally more robust to the inputs.\n",
        "\n",
        "Typically, a small amount of dropout can be applied after each VGG block, with more dropout applied to the fully connected layers near the output layer of the model.\n",
        "\n",
        "In this case, a dropout of 20% is applied after each VGG block, with a larger dropout rate of 50% applied after the fully connected layer in the classifier part of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc9iWP5scUTU",
        "outputId": "82938df5-5632-463f-9601-e3588c55bf66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2029 images belonging to 2 classes.\n",
            "> 69.591\n"
          ]
        }
      ],
      "source": [
        "# baseline model for the dogs vs cats dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(os.path.join(base_dir, filename + '_plot3VGGBlock_PlusDP.png'))\n",
        "\tpyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\t# prepare iterators\n",
        "\ttrain_it = datagen.flow_from_directory(os.path.join(base_dir, 'dataset_dogs_vs_cats/train/'),\n",
        "\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = datagen.flow_from_directory(os.path.join(base_dir, 'dataset_dogs_vs_cats/test/'),\n",
        "\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\t# fit model\n",
        "\thistory = model.fit(train_it, steps_per_epoch=len(train_it),\n",
        "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=40, verbose=0)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnN-FSMgffD9"
      },
      "source": [
        "Reviewing the learning curves, we can see that dropout has had an effect on the rate of improvement of the model on both the train and test sets.\n",
        "\n",
        "Overfitting has been reduced or delayed, although performance may begin to stall towards the end of the run.\n",
        "\n",
        "The results suggest that further training epochs may result in further improvement of the model. Please explore using a slightly higher dropout rate after the VGG blocks in addition to the increase in training epochs (50?)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpQ-7iZSf7oj"
      },
      "source": [
        "## Image Data Augmentation\n",
        "\n",
        "It is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset.\n",
        "\n",
        "Training deep learning neural network models on more data can result in more skillful models, and variations of the images can improve the ability of the fit models to generalize what they have learned to new images.\n",
        "\n",
        "Data augmentation can also act as a regularization technique, adding noise to the training data, and encouraging the model to learn the same features, invariant to their position-intensity in the input.\n",
        "\n",
        "Small changes to the input photos of dogs and cats might be useful for this problem, such as small shifts and horizontal flips. These augmentations can be specified as arguments to the ImageDataGenerator used for the training dataset. The augmentations should not be used for the test dataset, as we wish to evaluate the performance of the model on the unmodified photographs.\n",
        "\n",
        "This requires that we have a separate ImageDataGenerator instance for the train and test dataset, then iterators for the train and test sets created from the respective data generators. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3VA0G-ofg4Q"
      },
      "outputs": [],
      "source": [
        "# create data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
        "\twidth_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "# prepare iterators\n",
        "train_it = train_datagen.flow_from_directory(os.path.join(base_dir, 'dataset_dogs_vs_cats/train/'),\n",
        "\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "test_it = test_datagen.flow_from_directory(os.path.join(base_dir, 'dataset_dogs_vs_cats/test/'),\n",
        "\tclass_mode='binary', batch_size=64, target_size=(200, 200))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtqO_9ukmtCD"
      },
      "source": [
        "In this case, photos in the training dataset will be augmented with small (10%) random horizontal and vertical shifts and random horizontal flips that create a mirror image of a photo. Photos in both the train and test steps will have their pixel values scaled in the same way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96U8Bs7ymtzQ",
        "outputId": "e540c5f7-be66-499d-8de6-aa475566835b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2029 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import learning_rate_schedule\n",
        "# baseline model for the dogs vs cats dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(os.path.join(base_dir, filename + '_plot3VGGBlock_PlusDAG.png'))\n",
        "\tpyplot.close()\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generators\n",
        "\ttrain_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
        "\twidth_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\ttest_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\t# prepare iterators\n",
        "\ttrain_it = train_datagen.flow_from_directory(os.path.join(base_dir, 'dataset_dogs_vs_cats/train/'),\n",
        "\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\ttest_it = test_datagen.flow_from_directory(os.path.join(base_dir, 'dataset_dogs_vs_cats/test/'),\n",
        "\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
        "\t# fit model\n",
        "\thistory = model.fit(train_it, steps_per_epoch=len(train_it),\n",
        "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=40, verbose=0)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BHZQWwnq-_m"
      },
      "source": [
        "In this case, we can see a lift in performance of about 5% from about 80% for the baseline model to about 85% for the baseline model with simple data augmentation.\n",
        "Reviewing the learning curves, we can see that it appears the model is capable of further learning with both the loss on the train and test dataset still decreasing even at the end of the run. Repeating the experiment with 100 or more epochs will very likely result in a better performing model.\n",
        "\n",
        "Please explore other augmentations that may further encourage the learning of features invariant to their position in the input, such as minor rotations and zooms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Gs6o4ctYUt"
      },
      "source": [
        "## Findings\n",
        "\n",
        "Baseline VGG3 + Dropout: 81.279%\n",
        "\n",
        "Baseline VGG3 + Data Augmentation: 85.816\n",
        "\n",
        "Baseline VGG3 + DP + Data Augmentation: 85.816\n",
        "\n",
        "\n",
        "As suspected, the addition of regularization techniques slows the progression of the learning algorithms and reduces overfitting, but not in performance on the holdout dataset. It is likely that the combination of both approaches with further increase in the number of training epochs will result in further improvements.\n",
        "\n",
        "This is just the beginning of the types of improvements that can be explored on this dataset. In addition to tweaks to the regularization methods described, other regularization methods could be explored such as weight decay and early stopping.\n",
        "\n",
        "It may be worth exploring changes to the learning algorithm such as changes to the learning rate, use of a learning rate schedule, or an adaptive learning rate such as Adam.\n",
        "\n",
        "Alternate model architectures may also be worth exploring. The chosen baseline model is expected to offer more capacity than may be required for this problem and a smaller model may faster to train and in turn could result in better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI0GSrAkuG2k"
      },
      "source": [
        "## Transfer Learning\n",
        "It involves using all or parts of a model trained on a related task.\n",
        "\n",
        "Keras provides a range of pre-trained models that can be loaded and used wholly or partially.\n",
        "\n",
        "A useful model for transfer learning is one of the VGG models, such as VGG-16 with 16 layers that at the time it was developed, achieved top results on the ImageNet photo classification challenge [Li Fei Fei, Stanford University, creator of ImageNet: \"How we are teaching computers to understand images\"](https://www.youtube.com/watch?v=40riCqvRoMs).\n",
        "\n",
        "The model is comprised of two main parts, the feature extractor part of the model that is made up of VGG blocks, and the classifier part of the model that is made up of fully connected layers and the output layer.\n",
        "\n",
        "We can use the feature extraction part of the model and add a new classifier part of the model that is tailored to the dogs and cats dataset. Specifically, we can hold the weights of all of the convolutional layers fixed during training, and only train new fully connected layers that will learn to interpret the features extracted from the model and make a binary classification.\n",
        "\n",
        "This can be achieved by loading the VGG-16 model, removing the fully connected layers from the output-end of the model, then adding the new fully connected layers to interpret the model output and make a prediction. The classifier part of the model can be removed automatically by setting the “include_top” argument to “False“, which also requires that the shape of the input also be specified for the model, in this case (224, 224, 3). This means that the loaded model ends at the last max pooling layer, after which we can manually add a Flatten layer and the new clasifier layers.\n",
        "Not a lot of training will be required in this case, as only the new fully connected and output layer have trainable weights. As such, we will fix the number of training epochs at 10.\n",
        "\n",
        "The VGG16 model was trained on a specific ImageNet challenge dataset. As such, it is configured to expected input images to have the shape 224×224 pixels. We will use this as the target size.\n",
        "\n",
        "This not the only one, we can make use of other pre-trained models like: \n",
        "\n",
        "ResNet34\n",
        "\n",
        "ResNet50\n",
        "\n",
        "ResNet100\n",
        "\n",
        "[VVG16 and residual connections: Perceptual Losses for Real-Time Style Transfer and Super-Resolution\n",
        "Justin Johnson, Alexandre Alahi, Li Fei-Fei](https://cs.stanford.edu/people/jcjohns/papers/eccv16/JohnsonECCV16.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8zuQ4DAxyEm",
        "outputId": "7e2e71de-b4e1-442c-bf0b-e6c82379b3c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2029 images belonging to 2 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "125/125 [==============================] - 5291s 42s/step - loss: 0.4343 - accuracy: 0.9496 - val_loss: 0.0761 - val_accuracy: 0.9719\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 5131s 41s/step - loss: 0.0220 - accuracy: 0.9911 - val_loss: 0.0864 - val_accuracy: 0.9749\n",
            "Epoch 3/10\n",
            "  9/125 [=>............................] - ETA: 1:03:11 - loss: 0.0046 - accuracy: 0.9983"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "# define cnn model\n",
        "def define_model():\n",
        "\t# load model\n",
        "\tmodel = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
        "\t# mark loaded layers as not trainable\n",
        "\tfor layer in model.layers:\n",
        "\t\tlayer.trainable = False\n",
        "\t# add new classifier layers\n",
        "\tflat1 = Flatten()(model.layers[-1].output)\n",
        "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "\toutput = Dense(1, activation='sigmoid')(class1)\n",
        "\t# define new model\n",
        "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(os.path.join(base_dir, filename + '_plot16VGGBlock_TL.png'))\n",
        "\tpyplot.close()\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(featurewise_center=True)\n",
        "\t# specify imagenet mean values for centering\n",
        "\tdatagen.mean = [123.68, 116.779, 103.939]\n",
        "\t# prepare iterator\n",
        "\ttrain_it = datagen.flow_from_directory(os.path.join(base_dir, 'dataset_dogs_vs_cats/train/'),\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(224, 224))\n",
        "\ttest_it = datagen.flow_from_directory(os.path.join(base_dir, 'dataset_dogs_vs_cats/test/'),\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(224, 224))\n",
        "\t# fit model\n",
        "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
        "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=10, verbose=1)\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# save model\n",
        "\tmodel.save(os.path.join(base_dir,'final_model.h5'))\n",
        "\tprint(model.summary())\n",
        "\tmyfile = os.path.join(base_dir, 'model_plot.png')\n",
        "\tplot_model(model, to_file=myfile, show_shapes=True, show_layer_names=True)\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJYM1AIy-I4A"
      },
      "source": [
        "Reviewing the learning curves, we can see that the model fits the dataset quickly. It does not show strong overfitting, although the results suggest that perhaps additional capacity in the classifier and/or the use of regularization might be helpful.\n",
        "\n",
        "There are many improvements that could be made to this approach, including adding dropout regularization to the classifier part of the model and perhaps even fine-tuning the weights of some or all of the layers in the feature detector part of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6laeiMR-al1"
      },
      "source": [
        "## Using the Model to make predictions\n",
        "\n",
        "The process of model improvement may continue for as long as we have ideas and the time and resources to test them out.\n",
        "\n",
        "At some point, a final model configuration must be chosen and adopted. In this case, we will keep things simple and use the VGG-16 transfer learning approach as the final model.\n",
        "\n",
        "First, we will finalize our model by fitting a model on the entire training dataset and saving the model to file for later use. We will then load the saved model and use it to make a prediction on a single image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmLW_VDlCL5S"
      },
      "source": [
        "First, we can load the image and force it to the size to be 224×224 pixels. The loaded image can then be resized to have a single sample in a dataset. The pixel values must also be centered to match the way that the data was prepared during the training of the model. The load_image() function implements this and will return the loaded image ready for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE8vN6dQ-Hwy"
      },
      "outputs": [],
      "source": [
        "# make a prediction for a new image.\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "\n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = load_img(filename, target_size=(224, 224))\n",
        "\t# convert to array\n",
        "\timg = img_to_array(img)\n",
        "\t# reshape into a single sample with 3 channels\n",
        "\timg = img.reshape(1, 224, 224, 3)\n",
        "\t# center pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img - [123.68, 116.779, 103.939]\n",
        "\treturn img\n",
        "\n",
        "# load an image and predict the class\n",
        "def run_example():\n",
        "\t# load the image\n",
        "\timg = load_image(os.path.join(base_dir,'sample_image.jpg'))\n",
        "\t# load model\n",
        "\tmodel = load_model(os.path.join(base_dir,'final_model.h5'))\n",
        "\t# predict the class\n",
        "\tresult = model.predict(img)\n",
        "\tprint(result[0])\n",
        "\n",
        "# entry point, run the example\n",
        "run_example()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SQfryF8CtpR"
      },
      "source": [
        "EL FIN"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}